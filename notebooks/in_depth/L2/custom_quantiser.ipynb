{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom quantiser layer: W8A16LinearLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_int8 = torch.randint(-128, 127, (32, 16)).to(torch.int8)\n",
    "random_hs = torch.randn((1, 16), dtype=torch.bfloat16)\n",
    "scales = torch.randn((1,32), dtype=torch.bfloat16)\n",
    "bias = torch.randn((1, 32), dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  89.0000, -510.0000,  110.0000,  -57.7500,  -61.5000,  175.0000,\n",
       "          151.0000, -444.0000, -178.0000,  174.0000, -233.0000,  302.0000,\n",
       "          612.0000,  -92.5000,  392.0000,  612.0000,  -31.8750,  -37.5000,\n",
       "         -165.0000, -219.0000,  576.0000,  -93.0000,   92.5000,   52.0000,\n",
       "          188.0000,  235.0000,    3.7969,   65.5000, -472.0000,   41.0000,\n",
       "          -32.7500,   13.0625]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.linear(random_hs, random_int8.to(random_hs.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3400e+02,  1.6800e+02, -1.3100e+02,  1.0000e+01,  6.7500e+01,\n",
       "         -6.0250e+01,  7.4219e-02,  2.4800e+02,  3.6800e+02, -2.3100e+02,\n",
       "         -1.7700e+02, -1.6500e+02,  2.7400e+02, -1.8400e+02,  3.9800e+02,\n",
       "         -9.8000e+02,  5.0750e+01, -4.5750e+01, -6.8000e+01,  1.8600e+02,\n",
       "         -4.8600e+02, -1.4900e+02,  5.6250e+01, -1.0200e+02, -3.1600e+02,\n",
       "          0.0000e+00,  7.0000e+00, -2.8250e+01, -3.0600e+02, -6.9500e+01,\n",
       "         -3.1500e+01,  1.9750e+01]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.linear(random_hs, random_int8.to(random_hs.dtype)) * scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  28.0000, -191.0000,  -59.0000, -688.0000,  125.0000, -280.0000,\n",
       "          400.0000, -235.0000,  -92.0000,   -3.1406,   38.2500,  -28.6250,\n",
       "            8.4375,  227.0000,   11.5000,  104.5000,  204.0000,   73.0000,\n",
       "          -39.2500,   62.5000,  -34.7500, -175.0000,  240.0000,  160.0000,\n",
       "          -45.5000,  153.0000,   17.6250,  624.0000,   86.0000,   42.0000,\n",
       "          -35.5000,  107.0000]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(F.linear(random_hs, random_int8.to(random_hs.dtype)) * scales) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With bias:\n",
      "tensor([[  27.3750, -191.0000,  -59.0000, -688.0000,  126.0000, -280.0000,\n",
      "          402.0000, -234.0000,  -92.5000,   -3.8438,   37.2500,  -29.0000,\n",
      "            8.8125,  227.0000,    9.5000,  103.5000,  203.0000,   72.5000,\n",
      "          -38.2500,   63.5000,  -33.5000, -175.0000,  240.0000,  160.0000,\n",
      "          -44.5000,  154.0000,   14.4375,  624.0000,   85.0000,   41.2500,\n",
      "          -34.2500,  105.5000]], dtype=torch.bfloat16)\n",
      "Without bias:\n",
      "tensor([[  27.3750, -191.0000,  -59.0000, -688.0000,  126.0000, -280.0000,\n",
      "          402.0000, -234.0000,  -92.5000,   -3.8438,   37.2500,  -29.0000,\n",
      "            8.8125,  227.0000,    9.5000,  103.5000,  203.0000,   72.5000,\n",
      "          -38.2500,   63.5000,  -33.5000, -175.0000,  240.0000,  160.0000,\n",
      "          -44.5000,  154.0000,   14.4375,  624.0000,   85.0000,   41.2500,\n",
      "          -34.2500,  105.5000]], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "print(\"With bias:\")\n",
    "print(w8_a16_forward(input=random_hs, weight=random_int8, scales=scales, bias=None))\n",
    "\n",
    "print(\"Without bias:\")\n",
    "print(w8_a16_forward(input=random_hs, weight=random_int8, scales=scales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class W8A16LinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"int8_weights\", torch.randint(-128, 127, (out_features, in_features), dtype=torch.int8))\n",
    "        self.register_buffer(\"scales\", torch.randn((out_features), dtype=dtype))\n",
    "\n",
    "        if bias is not None:\n",
    "            self.register_buffer(\"bias\", torch.randn((1, out_features), dtype=dtype))\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    def w8_a16_forward(weight, input, scales, bias=None):\n",
    "        casted_weights = weight.to(input.dtype)\n",
    "        output = F.linear(input, casted_weights) * scales\n",
    "        if bias is not None:\n",
    "            output = output + bias\n",
    "        return output\n",
    "\n",
    "    def quantise(self, weights):\n",
    "        w_fp32 = weights.clone().to(torch.float32)\n",
    "        scales = w_fp32.abs().max(dim=-1).values / 127\n",
    "        scales = scales.to(w_fp32.dtype)\n",
    "\n",
    "        int8_w = torch.round(w_fp32/scales.unsqueeze(1)).to(torch.int8)\n",
    "        self.int8_weights = int8_w\n",
    "        self.scales = scales\n",
    "\n",
    "    def forward(self, input):\n",
    "        return w8_a16_forward(input=input, weight=self.int8_weights, scales=self.scales, bias=self.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = W8A16LinearLayer(16, 32)\n",
    "dummy_hidden_states = torch.randn(1, 6, 16)\n",
    "dummy_hidden_states.shape\n",
    "module(dummy_hidden_states).dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlquant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
